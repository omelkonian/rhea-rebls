%% Camera-ready
\documentclass[sigplan,screen,10pt]{acmart}

%% Copyright & Conference information
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmPrice{15.00}
\acmDOI{10.1145/3281278.3281279}
\acmYear{2018}
\copyrightyear{2018}
\acmISBN{978-1-4503-6070-8/18/11}
\acmConference[REBLS '18]{Proceedings of the 5th ACM SIGPLAN International Workshop on Reactive and Event-Based Languages and Systems}{November 4, 2018}{Boston, MA, USA}
\acmBooktitle{Proceedings of the 5th ACM SIGPLAN International Workshop on Reactive and Event-Based Languages and Systems (REBLS '18), November 4, 2018, Boston, MA, USA}

% Tikz
\usepackage{tikz}
\usetikzlibrary{arrows,fit,backgrounds,positioning}
\usepackage{environ}
\makeatletter
\newsavebox{\measure@tikzpicture}
\NewEnviron{scaletikzpicturetowidth}[1]{%
  \def\tikz@width{#1}%
  \def\tikzscale{1}\begin{lrbox}{\measure@tikzpicture}%
  \BODY
  \end{lrbox}%
  \pgfmathparse{#1/\wd\measure@tikzpicture}%
  \edef\tikzscale{\pgfmathresult}%
  \BODY
}
\makeatother

% Fonts
\usepackage{fontspec}
\setmainfont{LinLibertine}[
  Extension = .otf,
  Path = ./fonts/,
  UprightFont = *_R,
  BoldFont = *_RB,
  ItalicFont = *_RI
]
\setsansfont{LinBiolinum}[
  Extension = .otf,
  Path = ./fonts/,
  UprightFont = *_R,
  BoldFont = *_RB,
  ItalicFont = *_RI
]
% Colors
\usepackage{xcolor}
\colorlet{myrd}{ACMRed}
\colorlet{mygr}{ACMGreen}
\colorlet{mybl}{ACMLightBlue}
\colorlet{mybr}{ACMOrange}
\colorlet{myye}{ACMYellow}
% Images
\graphicspath{ {images/} }
% Code
\usepackage{minted}
% Extra
\usepackage{adjustbox}
\usepackage{url}

\begin{document}
\sloppy % for proper justification (no overflows to the right)
\input{MACROS.tex}

\title[RHEA]{RHEA: A Reactive, Heterogeneous, Extensible and Abstract Framework for Dataflow Programming}

%% Orestis
\author{Orestis Melkonian}
\orcid{0000-0003-2182-2698}
\affiliation{
  \department{Institute of Informatics and Telecommunications}
  \institution{NCSR ``Demokritos''}
  \city{Athens}
  \country{Greece}
}
\affiliation{
  \department{Information and Computing Sciences}
  \institution{Utrecht University}
  \city{Utrecht}
  \country{The Netherlands}
}
\email{o.melkonian@uu.nl}

%% Angelos
\author{Angelos Charalambidis}
\orcid{0000-0001-7437-410X}
\affiliation{
  \department{Institute of Informatics and Telecommunications}
  \institution{NCSR ``Demokritos''}
  \city{Athens}
  \country{Greece}
}
\email{acharal@iit.demokritos.gr}

\begin{abstract}
Robotics and IoT applications are perfect candidates that can benefit from
the functional reactive programming paradigm. Moreover, since a typical
program can be represented as a dataflow graph, the application can be conceptually
separated and distributed in different machines and the several graph partitions
can run in parallel and possibly in different execution stacks. In this paper
we propose a general-purpose reactive framework that can express complex
applications, seamlessly and transparently integrating different sources and
middlewares. The framework is abstract and extensible, making it easy to integrate
with well-established technologies that rely on the PubSub model. We demonstrate
the usability of the framework by providing application examples in the domain of
robotics and IoT.
\end{abstract}

%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML} <ccs2012> <concept>
<concept_id>10011007.10010940.10010971.10010972.10010545</concept_id>
<concept_desc>Software and its engineering~Data flow
architectures</concept_desc> <concept_significance>500</concept_significance>
</concept> <concept>
<concept_id>10011007.10011006.10011008.10011009.10011016</concept_id>
<concept_desc>Software and its engineering~Data flow languages</concept_desc>
<concept_significance>500</concept_significance> </concept> </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Data flow architectures}
\ccsdesc[500]{Software and its engineering~Data flow languages}
%% End of generated code

%% Keywords
\keywords{dataflow programming,
          stream processing,
          functional reactive programming (FRP),
          declarative languages,
          implicit concurrency,
          node placement}

\maketitle

\section{Introduction} \label{sec:introduction}

A typical application in robotics or Internet of Things (IoT) needs to timely and
continuously respond to time-varying external sensory data and, as a result, the
reactivity of these applications is imperative. Typically, the programmer of such
applications has to deal with asynchronous callbacks in conventional imperative
programming languages, in order to implement tedious and often error-prone behaviours
that should comply with the reactive requirements.

%\paragraph{Why FRP is popular and many systems embrace it}
A promising and relatively recent proposal for simplifying the implementation of
reactive applications is \emph{functional reactive programming} (FRP)~\cite{fran}.
FRP makes heavy use of higher-order functional operators to define, essentially, a
dataflow network of processing nodes. These high-level abstractions
alleviate, as intended, the low-level implementation chores. Although FRP was originally
proposed as a framework for developing graphical user interfaces, the key high-level
abstractions are generic enough that other domains can benefit from this
approach. As a result of its generality and its increasing popularity several
general-purpose implementations emerge with different capabilities and prerequisites.

It is natural, therefore, to investigate whether robotics and IoT applications
can fit into this new paradigm. Indeed, most robotic applications follow the
Robot Perception Architecture, where inputs to system are the robot's
sensors, which are then processed by a dataflow graph, whose output is given as
commands to the robot actuators. Moreover, robotics typically involve several
different other robotic or IoT systems to enhance their sensing abilities. These
combined applications make more evident issues of distributing the dataflow graph to
several robotic units and issues of heterogeneity and interoperability between
different middlewares and protocols.

The first steps towards using FRP in robotics was identified in \cite{arrows_robots}
and realized in Yampa\site{https://wiki.haskell.org/Yampa}, an FRP framework
developed in Haskell. Yampa provides its functionality through an embedded DSL,
as is customary for many of the FRP libraries. Although an interesting proposal,
there is limited acceptance from the robotics community, mainly because it does
not integrate well with existing well-established robotics middlewares such as
the Robot Operating System (ROS) \cite{ROS}. As a result, legacy algorithms should be
written from scratch in this new library. Moreover, it does not assume integration
with other reactive systems via the Reactive Streams Standard (RSS)\site{http://www.reactive-streams.org}
which is essential for applications that need multiple heterogeneous sources.

Motivated by the robotics and IoT community we propose \textsc{RHEA}, an abstract
FRP general-purpose framework that aims to act as a unifying layer that can
be mapped and executed using different reactive libraries and existing middlewares
such as ROS and MQTT\site{http://mqtt.org/}. The programmer can transparently express complex reactive
applications within this framework that may use both sensing from several robots
and IoT sensors. The framework places the dataflow nodes to computational resources
and handles the serialization needed between different execution engines.

%\paragraph{Structure of the paper}
The rest of the paper is structured as follows.
Section~\ref{sec:background} provides some background context about dataflows and
the state-of-art middlewares used in robotics and IoT.
Section~\ref{sec:approach} presents the framework's architecture and capabilities.
Section~\ref{sec:implementation} discusses implementation details followed by
Section~\ref{sec:optimization} which presents several optimizations that have
been implemented in the framework. Section~\ref{sec:applications} demonstrates
some use-cases of the framework mainly motivated by robotics and IoT.
Section~\ref{sec:related} discusses related work and finally
Section~\ref{sec:conclusions} concludes with future directions.

\section{Background} \label{sec:background}
In this section we provide some necessary background context. In particular, we
briefly present the dataflow model and the notation of graphs we use in the
remaining sections. We continue with a brief overview of the well-established
middlewares used in robotics and IoT, namely the Robot Operating System (ROS)
and the Message Queuing Telemetry Trasport (MQTT) protocol.
For the rest of the paper we assume however familiarity with functional
reactive programming (FRP).

\subsection{The Dataflow Computational Model}
In the dataflow computational model, the program is represented as a dataflow graph, where
nodes are independent computational units and edges are communication channels
between these units. A node is fired immediately when its required inputs are
available and therefore no explicit control commands are needed for execution.
An immediate consequence is that the nodes of the graph can run independently
and potentially in parallel as soon as their inputs are present.

%\begin{example}
Figure~\ref{fig:nat} shows a dataflow graph enumerating the set $\mathbb{N}$ of
natural numbers.
%
\mydiag{nat}{Natural numbers}
%
In the dataflow graph above, we can discern three types of nodes: sources, which
do not have any incoming edge and act as value generators to initiate
computation, sinks, which do not have any outgoing edges and inner nodes, which
transform one or more incoming streams and redirect their output to other nodes.
The \textit{zero} node just produces a stream with a single value 0 and then
terminates. \textit{Concat} produces a single stream by concatenating the stream
produced by \textit{zero} and \textit{increment}, while \textit{increment}
transforms its input stream by adding one to its values. Finally, the sink node
displays the result, which is the stream of natural numbers.

Streams can be infinite, such as the stream produced by \textit{concat} because
it is the concatenation of a single-value stream and an infinite one. Moreover,
the graph is cyclic as \textit{concat} feeds input to \textit{increment} and
vice versa. The most interesting fact is that there nodes are independent and
therefore can run in parallel. For instance, while \textit{increment} is
processing value 5 (i.e. to produce value 6), the previous result (i.e. value 5)
passes through \textit{concat} to reach the sink node, which can concurrently
process it to display it.
%\end{example}

%begin{example2}
As a more involved example, consider the problem of enumerating the
\textit{Hamming numbers}, which are generated by the mathematical formula
$\mathbb{H} = 2^i3^j5^k$, where $i,j,k \in \mathbb{N}$. Figure~\ref{fig:hamming}
depicts an intuitive dataflow solution to the above problem, borrowed from the book of Lucid~\cite{lucid}.
%
\mydiag{hamming}{Hamming numbers}
%end{example2}

Dataflow graphs can be executed both in a single machine and in a cluster of
machines where each node can be placed in a different machine. A possible
single-machine implementation could represent edges as in-memory queues,
whereas a multi-machine one could realize them as channels between TCP sockets,
allowing communication across the network.

\subsection{Robotics and IoT Middlewares}
In the following we briefly present the ROS and MQTT, the de-facto middlewares
used in robotics and IoT. The architecture of both follow a topic-based
publish-subscribe (PubSub) pattern to loosely couple different processes and
at the same time maximize flexibility.

\subsubsection{ROS}
\textit{ROS} is an open-source middleware for robot software, which emphasizes
large-scale integrative robotics research~\cite{ROS}. It provides a \textit{thin}
communication layer between heterogeneous computers, from robots to mainframes
and it has been widely adopted by the research community around the world, due
to its flexibility and maximal support of reusability through packaging and
composability. It provides a compact solution to the development complexity
introduced by complex robot applications that consist of several modules and
require different device drivers for each individual robot.

It follows a peer-to-peer network topology, implemented using a topic-based
\textit{PubSub} messaging protocol and its architecture reflects many sound
design principles. Another great property of \textit{ROS} is that it is
language-agnostic, meaning that only a minimal specification language for
message transaction has been defined, so contributors are free to implement
small-size clients in different programming languages, with \textit{roscpp} for C++
and \textit{rospy} for Python being the most widely used ones.

A typical development scenario is to write several \textit{nodes}, that
subscribe to some topics and, after doing some computation, publish their
results on other topics. The main architectural issue here is that subscribing
is realized through asynchronous callback functions, so complicated schemes
easily lead to unstructured code, which obviously lead to unreadable and
hard-to-maintain code. Our approach gives a solution to the aforementioned
problem.

\subsubsection{MQTT}
Internet of Things (IoT) conveys the concept of a multitude of heterogeneous devices,
ranging from low-cost sensors to vehicles with embedded electronics, are connected and
provide the ability to collect data and exchange it amongst themselves.
The development of such systems though, due to their heterogeneity, is rather
complex and costly. Recent development of a variety of middleware frameworks,
showed that a standard protocol of communication is imperative along with supporting
tools~\cite{iot_middleware}.

The most widely spread protocol is \textit{MQTT}, which follows the \textit{PubSub}
messaging pattern and provides a very minimal and lightweight communication layer
in order not to put a strain on the resource-bounded system~\cite{mqtt}.
For instance, an \textit{IoT} application could connect to some sensors by
subscribing to their corresponding topics, taking decisions that would result in
some commands to some actuators, by publishing to their corresponding topics.

Fortunately, the dataflow model seems to be rather fitting for these
scenarios~\cite{iot_dataflow}, as every node in the graph is completely
independent, and consequently can be any "\textit{thing}". This useful property
of the model makes it a good architectural choice for such applications. The
only thing to consider is how these things will communicate in a standard way,
so as to be able to add new types of \textit{things} and integrate it in an
effortless way to an existing dataflow network.

\section{The RHEA Framework} \label{sec:approach}

In this section, we set out our main design goals and provide an overview
of the system architecture and the DSL.

\subsection{Requirements and Objectives} \label{sec:requirements}

%\paragraph{Reactive}
The proposed system should be \textit{reactive}, relying solely on asynchronous
message-passing for inter-component communication leading to loose coupling,
isolation, location transparency and error propagation.

%\paragraph{Heterogeneous}
One of the major concerns while designing the framework was the ability to
deploy it anywhere, from low-cost robots to mainframes. Apparently such
attribute would require a very flexible runtime environment that have the ability to handle
\textit{heterogeneous} devices.

%\paragraph{Extensible}
As the new technologies and frameworks arise the system should be able to adapt
and be extended in order to remain useful and general-purpose.
Therefore, careful consideration was taken to compose the system of different
independent modules, which could \textit{extensible} and easily modified. With that concept
in mind, generality and abstraction were heavily emphasized during both the design
and the implementation process.

%\paragraph{Abstract}
The framework should be also \textit{abstract} in terms of implementation details,
as it is completely agnostic of any machine-specific requirements. It is designed as a
unifying conceptual base for further extensions and careful consideration was
taken not to restrict it in any aspect.

\subsection{Architecture}
The \textsc{RHEA} framework consists of several clearly separated modules,
whose interconnection is illustrated in Figure~\ref{fig:architecture}.
%
\begin{figure*}
  \centering
  \includegraphics[scale=0.6]{architecture}
    \caption{System architecture}
    \label{fig:architecture}
\end{figure*}

A typical workflow of the system is as follows. The user writes a program in
the provided domain-specific language, which constructs an internal representation
of the dataflow graph. Afterwards, using information about the available
resources in the network, the constructed graph is optimized and partitions of the
graph are assigned to physical computational resources. The optimized graph partitions are
then distributed across the available machines for execution, maybe using a
different evaluation strategy each time.

More specifically, a flexible evaluation strategy was employed where different
executors can be considered when available. This design satisfies the requirements
of extensibility, heterogeneity and abstraction of the system since each partial
graph can be evaluated by a different \java{EvaluationStrategy} which could
interpret it using a specific streams library or even compile into CUDA code
for execution on a GPU. In Section~\ref{sec:implementation} we provide three
different evaluation strategies.

\subsection{Dataflow Graphs}

We will now present the graph construction using the DSL of RHEA and
demonstrate the key supported features of the available operators. We opted to
do that by illustrative examples, rather than providing a formal specification.
While the examples are written in Java, any other JVM language would do.

The kind of dataflow graph that can be expressed using the framework's stream
language are directed cyclic graphs with possibly many inputs and outputs.
%
%\paragraph{The Stream data type}
The data channels (i.e. edges of the dataflow graph) are represented using the
\java{Stream} data type, which is parametric, meaning that it can emit values
of any data type, whether built-in or user-defined. The stream produced may
terminate, successfully or erroneously, or even be infinite.

%\paragraph{Graph construction syntax}
The construction of the internal dataflow graph is implicit, through a
rich set of operators on the Stream data type. Each \java{Stream} object
contains internally a dataflow graph of type \java{FlowGraph}, which is only
to be accessed and manipulated by the internal module, evaluation strategies and
optimizers. Therefore, an application developer only needs to work with the
\java{Stream} type.

Source nodes are constructed using built-in functions of the \java{Stream} type.
For instance, \java{Stream.just(1,2,3)} produces the stream that emits just
the values 1, 2 and 3. The return variable of this creation function is an
object of type \java{Stream}.

Processing nodes can be divided into two classes: \textit{single input} ones and
\textit{multiple input} ones.
%
Single input nodes are inserted into an existing \java{Stream} object, by
calling an operator on that object.
Multiple input nodes are constructed by built-in function that take as
argument already existing \java{Stream} objects.

\codefigg{singleinput}{\jvs{code/singleinput.java}}{Single input processing node}
%
\codefigg{multipleinput}{\jvs{code/multipleinput.java}}{Multiple input processing node}
%
Figure~\ref{fig:singleinput} shows an
example of a single input node, namely that of \java{map}, which transforms
the input stream (i.e. just the values 1, 2 and 3) by applying a user-defined
function to every emitted value.
%
Figure~\ref{fig:multipleinput} shows
an example of a multiple input node, namely that of \java{zip}, which
transforms the input streams by
applying a user-defined function to each emitted pairs of values.
Here we also see the stream creation function \java{Stream.range}.
%

The variables returned by all processing nodes are \java{Stream} objects. These
objects can be reused in different parts of the graph to enable splitting a
node's output to different processing nodes or outputs. Figure~\ref{fig:split}
shows such an example, where the \java{filter} operator only emits values for
which the given function returns true.

Cycles are constructed using the \java{loop} operator, which is a single
input processing node. It requires a function that, given an input stream,
constructs a subgraph that redirects its output to that input, therefore
creating a feedback loop. Figure~\ref{fig:natt} shows an example of the
\java{loop} operator to represent the natural numbers, just as the graph
shown earlier in Figure~\ref{fig:nat}. The \java{concat} operator is a
multiple input node that concatenates its input streams.

\codefigg{split}{\jvs{code/split.java}}{Split example}
\codefigg{natt}{\jvs{code/natt.java}}{Cyclic example}

%\paragraph{Evaluation syntax and semantics}
Lastly, to evaluate a given dataflow graph and do something with its output values, we
need to call the \java{subscribe} method of the \java{Stream} object and pass as argument
a user-defined action (i.e. function with side-effects).
%
%The execution is completely asynchronous, hence the order of stream
%declaration and evaluation does not matter at all.

\section{Implementation} \label{sec:implementation}

Since extensibility is a major design priority, most individual critical
components are defined using the Strategy design pattern, isolating the desired
functionality in a separate interface and allowing the system to select the
appropriate instantiating classes at runtime. The main pluggable components of
the system, for which default implementations are already provided by the
current implementation as separate libraries, are \textit{Evaluation},
\textit{Optimization}, \textit{Distribution}, \textit{Serialization} and
\textit{Network Profiling}. The source code for all RHEA components
is publicly available on Github\site{https://github.com/rhea-flow}.

%\paragraph{Notifications}
Every value passed through the framework's streams is wrapped inside a
\java{Notification} object, which discriminates stream values into three
categories: \java{onNext} (when the stream provides a regular value),
\java{onError} (when an error occurs) and \java{onComplete} (when the
stream completes its output). This enables the system to gracefully handle
error propagation.

In order to make the framework easy to integrate with other stream and
dataflow technologies, every input and output node implements the interfaces
that RSS defines, namely the Publisher and the Subscriber interface. This also
enables users to define new types of sources or sinks, in order to integrate
the framework with other general technologies (e.g. system events, HTTP requests,
PubSub implementations, etc).
%
In particular, a sink node (output) should implement the Subscriber interface, which
essentially defines three methods corresponding to reactions to a
\java{Notification}, one for each of the categories mentioned above.
%
Moreover, a source node (input) should implement the Publisher interface, which defines a
single method \java{subscribe(Subscriber)}, where a Subscriber requests the
Publisher to start emitting values.

Many existing technologies provide these interfaces, or at least adapters from
their internal representations, and therefore they are very easy to be
integrated to the framework.

\subsection{Execution}

Every primitive operator corresponds to an expression implementing the
\java{Transformer} interface and a complete dataflow is defined by a
\java{Stream} variable and an object implementing the \java{Output} interface,
which can be either an \java{Action}, a \java{Sink} or a list of these.

Roughly speaking, the \java{EvaluationStrategy} interface accepts the
\java{Stream} variable and its corresponding \java{Output} and executes it,
however desired. The strategies we have implemented so far follow:
\begin{description}
\item[RxJavaEvaluationStrategy]
which uses RxJava~\site{http://github.com/ReactiveX/RxJava}, an established and well-maintained library for
asynchronous programming using the \textit{Observable} type, which is very close,
semantically, to our \textit{Stream} type.

\item[RosEvaluationStrategy] which integrates the \textit{ROS} middleware into the
framework. This strategy's main objective is to set up a \textit{ROS} client and
configure every \java{RosTopic} used within the dataflow that needs to be
evaluated to use this client. After that, evaluation is propagated to a generic
strategy, for example, to RxJavaEvaluationStrategy.

\item[MqttEvaluationStrategy] which integrates the MQTT middleware into the
framework, in the same way \textit{ROS} is integrated.

\end{description}

\subsection{Distributed Execution} \label{sec:distributed}

An evaluation strategy executes the requested dataflow graph in a single
machine, without concern about distribution and resource utilization.
%
For distribution and cluster management, one needs to implement
the \java{DistributionStrategy} interface by adjusting the granularity (i.e. size) of
the graph to evaluate to fit the available resources (see, Section~\ref{sec:optimization})
and partition it across all computational resources, maybe using different evaluation strategies.

%\paragraph{Hazelcast}
The default \java{DistributionStrategy} uses the \textit{Hazelcast}\site{http://hazelcast.org/}
library to discover and manage multiple machines and used its internal decentralized PubSub model
to communicate intermediate results across the network. Figure~\ref{fig:partition}
illustrates the partitioning of a dataflow graph over several machines, where each
machine -- except the last one -- outputs its result to a Hazelcast topic,
from which another machine gets its input.
%
\optimizationL{2}{partition}{Partitioning}

%\paragraph{Machine configuration}
According to the distribution strategy being used, the available machines will
require a certain initial configuration. For the Hazelcast case, a
little piece of setup code needs to be executed on every member of the cluster,
which is together with the main \java{EvaluationStrategy} class. Moreover, helpful
information can also be added at this step, such as number of CPU cores. It is
the distribution strategy's responsibility to ensure that this information is
properly distributed and handled.

Apart from this initial configuration, the distribution strategy needs to enable
members to declare certain capabilities that they possess, which are required by
specialized nodes. For instance, a source node emitting values from a ROS topic
must be executed on a machine having ROS installed, in order to set up a ROS
client. The default implementation uses strings to represent capabilities and
are declared in the initialization code of each machine separately.

\subsubsection{Serialization}
As communication between machines across a network is mandatory, data types
emitted through the streams must be serialized on departure and de-serialized on
arrival at each machine. For this reason, each \java{DistributionStrategy}
must be configured with a class implementing the \java{Serializer} interface,
but we also provide a default one that covers most datatypes.
Figure~\ref{fig:serialization} depicts the serialization process in more detail.

\mydiag{serialization}{Serialization process}

\section{Optimizations} \label{sec:optimization}

This section describes three stages of optimization that the dataflow graph goes
through before being evaluated:
\begin{itemize}
  \item proactive filtering that places filtering operations as soon as possible;
  \item granularity adjustment that combines adjacent operation into a single more efficient operation;
  \item and node placement that places nodes that should be collocated to the same machine.
\end{itemize}
The optimization phases run sequentially, that is the output of one phase becomes
input of the next. The main purpose of the optimization graph is to achieve better
performance and better utilization of the available resources.

\subsection{Proactive filtering}
The first optimization stage is a heuristic one, based on the fact that if a
filter operation can be moved earlier (i.e. closer to source nodes) while
preserving the original semantics, then there will be benefit concerning
computational cost and cross-machine communication overhead. Figures~\ref{fig:maptake}-\ref{fig:concatdistinct}
illustrate one representative example of each general class of
graph transformation.

\optimization{1}{maptake}{Take/skip/distinct before map}
\optimization{1}{mapfilter}{Filter before map}
\optimization{3}{concatdistinct}{Filter/distinct before concat/merge}

\subsection{Granularity adjustment}
Each different node of the dataflow graph will be executed on a separate
thread/process. The fact that graphs can grow very big, for instance when
programming a swarm of robots, poses a problem when available
computational resources are limited. For this reason, the second optimization
stage tries to adjust the granularity of the dataflow graph to a desired value,
which is normally the number of available threads amongst all machines.
To reach the desired granularity, the optimizer applies some semantic-preserving
transformation, as shown in the figures~\ref{fig:mergemap}-\ref{fig:combzipmap}.

\optimization{1}{mergemap}{Merge maps}
\optimization{1}{combmapfilter}{Combine map with filter}
\optimization{1}{combfilterexists}{Combine filter with exists}
\optimization{1}{combmapexists}{Combine map with exists}
\optimization{2}{combmapzip}{Combine map with zip}
\optimization{1}{combzipmap}{Combine zip with map}

In Figure~\ref{fig:mergemap} we merge two \java{map} operations into
one \java{map} operation that uses the composition of the two initial
functions, while in Figure~\ref{fig:combmapfilter} a \java{map} followed
by a \java{filter} is substituted by a more complex equivalent operation,
namely \java{filterMap}. In Figures \ref{fig:combfilterexists} and
\ref{fig:combmapexists} we apply some simple properties of the boolean functions
involved to decrease the number of nodes. Lastly, in Figures \ref{fig:combmapzip} and
\ref{fig:combzipmap} we utilize function composition to embed \java{map}
operations into \java{zip} operations.

\subsection{Node placement}

After the first two passes, we have an optimized dataflow graph with fine-tuned
granularity. At this stage, nodes are mapped to tasks and are deployed across
the available machines, keeping resource utilization in mind.
If the desired granularity has not been reached yet, the
\java{DistributionStrategy} applies fusion to pairs of tasks until it reaches
it, as shown in Figure~\ref{fig:fusion}.
%
\optimization{1}{fusion}{Task fusion}

The final decision to be made is where each of these newly constructed tasks
will be executed, although some of them need to necessarily be placed on
specific machines with certain skills.

Apart from these hard constraints, we need to minimize communication overhead.
For this purpose, one must implement the \java{NetworkProfileStrategy} by providing
a way to calculate network distance between available machines, which is then
fed as input to the \java{NodePlacement} optimizer.

\section{Applications} \label{sec:applications}

This section provides two non-trivial example applications, in order to demonstrate
the expressiveness of our DSL.
While we have not deployed the code to actual robotic/IoT devices, we have tested
them against real-time recorded data, which realistically emulate these devices.

\subsection{Robot control panel}

This application concerns real-time monitoring of a robot, that is publishing
its information and sensor-data to ROS topics, through a
graphical user interface (GUI).

The \java{/camera/rgb} topic provides the frames of the robot's camera as
coloured images, while the \java{/camera/depth} provides frames that provide
depth information. The \java{/tf} topic publishes parent-child relations of
the internal topics of the robot's configuration, and finally the
\java{/scan/} topic provides information from the robot's laser that gives
horizontal depth information in polar coordinates.

The GUI displays the laser data embedded on the camera stream, while allowing
for real-time face detection. Additionally, it displays the depth frames and the
\java{tf} relations as a tree. Finally, a mock-up battery bar is displayed to
show-case the framework's ability for simulation. Figure~\ref{fig:control_panel}
illustrates the dataflow solution to the above problem and its corresponding
\textsc{RHEA} code.
%
\codefig{control_panel}{\ljvxs{code/control_panel.java}}{Robot control panel}

The implementation details (i.e. the visualization class and methods
\java{faceDetect} (line 6), \java{embedLaser} (line 7) and
\java{toGray} (line 14) are not shown for brevity's sake. It is worth noting
that this model of programming encourages a clean separation of concerns between the
individual components, namely between the sensor data manipulation and the
actual visualization on the GUI.

\subsection{Robot hospital guide}

As a final example, we will examine a combined application that involve both robotics and IoT.
Consider a robot that guides patients to different parts of a hospital, such as the gym or
cafeteria. We assume also that the map localization, path finding and obstacle
avoidance are already implemented and provided by default by ROS. The problem
is to calibrate the robot's speed according to the patient's status.
%
In order to keep track of the patient's distance from the robot, each patient carries a
smartphone that acts as a bluetooth low-energy (BLE) beacon. The robot uses its
bluetooth receiver to publish the distance from the signal source to an
MQTT topic, which is then transformed by our stream application to velocity
commands for the robot, in the form of slowing down or speeding up.

The first module constitutes the main program logic, where a declared dataflow
graph acts as a stream transformation from beacon information to velocity
commands to the robot. Figure~\ref{fig:hospital} shows the dataflow graph with
its corresponding \textsc{RHEA} code.

\codefig{hospital}{\ljvxs{code/hospital.java}}{Hospital guide: Robot control}

The second module (Fig.~\ref{fig:rxbeacon}) uses the library
\textit{ReactiveBeacons}\site{http://github.com/pwittchen/ReactiveBeacons}
to get a stream of beacon data via RxJava, and then publishes it to a MQTT topic,
which is the input of the first module. This example showcases the framework's ability
to combine different technologies and act as a high-level, declarative unified layer.

\codefigNodiagram{rxbeacon}{\ljvxs{code/rxbeacon.java}}{Hospital guide: RxJava-MQTT integration}

\section{Related Work} \label{sec:related}

\subsection{Dataflow systems}

The necessity for implicit parallelism and distribution of more and more
applications, dealing with huge and/or complex data, has brought increasingly
more attention to the dataflow programming model. Nowadays there are various
implementation of dataflow systems focused on different applications such as
Big Data batch and stream processing, Machine Learning and others.
In the following we discuss the prominent dataflow systems and the similarities
and differences with the proposed framework \textsc{RHEA}.

%\paragraph{Spark}
The two most prominent dataflow framework for scalable large-data processing
is Apache Spark~\cite{spark} and Apache Flink~\cite{stratosphere}. Both support
a rich set of data-parallel operators and can be used for either batch or
stream processing. They follow the same general approach as \textsc{RHEA} by
implicitly creating a dataflow pipeline. It is also worth noting that Apache Flink
optimizes the dataflow graph by applying semantically-equivalent graph rewriting~\cite{blackbox}.
Apart from these similarities there are also key differences.
They focus on providing a full execution stack and therefore they do not
provide the flexibility in using
existing  underlying system to perform execution. They accomplish distributed
execution by partitioning on the data in contrast to \textsc{RHEA} that partitions
the graph on the operations.

Similar to the flexibility that \textsc{RHEA} aims to provide is the project
Apache Beam~\cite{DBLP:journals/pvldb/AkidauBCCFLMMPS15}, formerly known as Cloud Dataflow and an evolution of FlumeJava~\cite{flumejava}.
Apache Beam shares the same key idea with \textsc{RHEA} namely they provide a
unified abstract programming layer for batch and stream processing that can use
multiple executors. They provide, for instance, an Apache Spark and an Apache Flink
executor. However, we assume that the cluster is homogeneous and thus the whole
program is executed using a single executor. Another framework that shares the
same similarities with Apache Beam and RHEA is dispel4py~\cite{dispel4py}, a Python
framework that focuses on scientific workflows. It provides the ability
to describe abstract workflows for distributed data-intensive applications.
Similar to the \textsc{RHEA} evaluation strategy concept, it allows different mappings
to enactment systems, such as MPI and Apache Storm. However, it does not tackle
heterogeneity issues and simultaneously executing graph partitions to different
enactment systems.

Another dataflow framework from Google is TensorFlow \cite{tensorflow},
which is an open-source polyglot library for machine intelligence and especially
construction of neural networks. Tensorflow differs from the aforementioned dataflow
systems since it assumes that data are Tensors, namely multidimensional arrays,
the nodes operate in Tensors and the program is a dataflow network of such operations.
Tensorflow is similar to \textsc{RHEA} since it is inherently heterogeneous by
considering different hardware devices such as CPU and GPUs. Moreover, it provides
distributed execution by partitioning the dataflow graph similarly to what \textsc{RHEA}
is proposing. The main difference compared to \textsc{RHEA} approach is that the
system is not reactive, therefore it is not optimized for asynchronous stream of
events.

Regarding the reactive-aware systems, RxJava and AkkaStreams are the most mature
frameworks that support programming languages that target the JVM. It is worth
mentioning \textit{Akka}~\site{http://akka.io} which is the foundation library
where AkkaStreams relies on. In particular, Akka is a toolkit and runtime for highly
concurrent, distributed and resilient message-driven applications and its execution
model follows the Actor model. In this model one perceives abstract computational
agents, called actors, that are distributed in space and communicate with
point-to-point messages. In reaction to a message, an actor can create more actors,
make local decisions, send more messages and determine how to respond to the next
message received. Similar to the problem of \textit{ROS} that our framework solved,
using Actors can be daunting. AkkaStreams try to provide a higher-level abstraction
from the Actor model and specifically it provides a convenient API for stream
processing and also dataflow graph construction.
The difference with \textsc{RHEA} is that AkkaStreams solely relies on Akka. On the
other hand, \textsc{RHEA} offers the ability to choose between several
evaluation strategies to match the application's needs.

Is is also worthwhile to mention \textit{Ziria}, a dataflow DSL for wireless
systems programming, which manages to replace low-level code with high-level
declarative code without loss of performance~\cite{ziria}.

\subsection{Robotics and IoT}

It is only natural that the dataflow model would make its way through the field
of robotics, as many behaviours in control theory are expressed as dataflow
diagrams.

%\paragraph{roshask}
\textit{Roshask}~\cite{roshask} is a binding from the Haskell programming language
to the basic \textit{ROS} interfaces. Like \textsc{RHEA}, the approach is to
overcome the shortcomings of \textit{ROS} callbacks by viewing topics as
streams. This allows for, and encourages, a higher level of abstraction in
robot programming, while making the fusing, transforming and filtering of
streams fully generic and compositional.
%\paragraph{Yampa}
\textsc{RHEA} and \textit{roshask} were heavily influenced by the work of Hudak's
group (Yale Haskell Group) on robot DSLs and FRP in general~\cite{fran,arrows_robots,lambda_in_motion}.
\textit{Yampa}~\cite{arrows_robots} is a DSL embedded in Haskell
that realizes the FRP model, using arrows to minimize time and space leaks.

%\subsection{Internet of Things}

IoT applications often deal with much heterogeneity, due to the variety of
sources that different devices introduce. Therefore, a component-based approach
suits well to solve this problem and there are some dataflow frameworks that
follow that approach.
%\paragraph{Node-RED}
Another interesting \textit{IoT} framework that follows a dataflow
approach is \textit{Node-RED}~\cite{iot_dataflow}, which is a visual tool for wiring
together hardware devices, APIs and online services in new and interesting ways.
Applications called flows, are built immediately on a browser, and can be
deployed on the Cloud with just a single click. The main advantage of this tool
is that it encourages social development, due to the fact that flows are stored
in JSON format, which can be easily imported and exported for sharing with
others.

\section{Conclusions and Future Work} \label{sec:conclusions}

The framework described in this paper offers a unified and extensible way for
reactive applications to be developed. Primarily motivated by the well-established
middlewares in robotics and IoT, the main focus of the framework is extensibility
and heterogeneity. To that end, a constant effort to generalize and make components
as abstract as possible was made.

The applications demonstrated the framework's ability to provide a higher level
of abstraction, where the language only specifies how different components
coordinate, without knowledge of the implementation details. 
Like \textit{Ziria}, our belief is that certain domains have
fixated their methods on low-level programming, whereas more satisfactory
paradigms can solve many shortcomings.

The set of operators aided expressibility, making it possible to specify any
dataflow graph in a concise and readable manner. This disallowed optimizations
suitable for less expressive models, but recent research suggest that general
dataflow topologies have optimization opportunities that are yet to be
found~\cite{blackbox}. In the current reincarnation of the framework only
a minimal optimization stage has been implemented, which nevertheless paves
the path to more advanced optimization techniques, such as the stream
fusion techniques proposed in \cite{streamfusion} and \cite{haskellfusion},
as well as those used in Apache Flink~\cite{blackbox}.

Apart from a more sophisticated optimization phase that can be investigated
as a future direction, there are also other extensions that are equally interesting
and challenging. Again motivated by the robotics domain, an interesting extension
is to apply dynamic reconfiguration where the applications operate in
environments that are constantly changing. For instance operating in an environment
where battery powered robots participate or the connectivity of the cluster is unstable.
Adaptive techniques for reconfiguring the dataflow graph distribution should be
devised in such situations. Morover, these environments give rise to fault-tolerant
execution and it is certainly challenging to propose methods for graceful recovery.

Lastly, another interesting future direction is alternative techniques regarding
node placement. It is worth investigating techniques that use reinforcement learning
to decide a reasonably efficient node placement, as recently proposed in~\cite{reinforcement}.

\begin{acks}
We would like to thank Panos Rondogiannis and Bill Wadge for valuable discussions,
as well as Stasinos Konstantopoulos and Giorgos Stavrinos for their insights on the ROS platform.
Last but not least, we thank the anonymous reviewers for their comments and suggestions.

The work was partially funded by the Utrecht University Fund (Utrechts Universiteitsfonds).
\end{acks}

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
\citestyle{acmnumeric}
%% Bibliography
\bibliography{rhea}

\end{document}
